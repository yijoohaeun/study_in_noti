{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c61c5aa4-ad65-44e8-8cc5-fc3f85cd7565",
   "metadata": {},
   "source": [
    "Q. gridsearch란 무엇이고 사용 방법에 대해 설명하라\n",
    "\n",
    "A. 모델의 최적 하이퍼 파라미터를 찾기 위한 기법 중 하나  \n",
    "      => 다른 방법은? \n",
    "  => 이 중에서 gridsearch를 설명한 이유?\n",
    "\n",
    "사용방법\n",
    "1. 하이퍼 파라미터 그리드 생성\n",
    "2. 정의한 하이퍼 파라미터 그리드 기반으로 가능한 모든 조합을 탐색하여 조합을 여러번 학습하며 각 조합에 대해 교차 검증을 수행\n",
    "3. 교차검증을 통해 나온 조합의 성능을 평가. 이 때 평가 지표로 정확도, 정밀도, 재현율, f1 score 등 다양한 성능 평가 지표를 사용 가능함\n",
    "4. 가장 우수한 성능을 보이는 하이퍼 파라미터 조합을 선택하고 해당 조합으로 최종 모델을 학습\n",
    "\n",
    "장점\n",
    "1. 구현이 간단하고 직관적이며 사용하기 쉬움\n",
    "2. 모든 하이퍼파라미터 조합을 탐색\n",
    "3. 평가 지표를 기반으로 최적화\n",
    "\n",
    "단점\n",
    "1. 그리드에 포함된 모든 조합을 탐색하기 때문에 계산 비용이 높음\n",
    "2. 튜닝할 하이퍼 파라미터 수의 제한\n",
    "3. 하이퍼 파라미터간의 관계를 고려하지 않고 독립적으로 탐색\n",
    "\n",
    "=> 단점 해결 방법?\n",
    "\n",
    "배깅이 약한 학습기 합치는 방식, 부스팅이 모델 1개를 예측하고 부정적인 샘플에 가중치줘서 점차 성능이 좋아지도록 훈련시키는 (샘플에 가중치 부여!) 방식.. \n",
    "\n",
    "gradient boosting: 잔차의 오차를 줄여가며 모델 강화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a240e31a-8d1e-422b-b9af-4e070b9fbc4d",
   "metadata": {},
   "source": [
    "# 산탄데르 고객 만족 예측\n",
    "* ROC-AUC로 평가 (대부분이 만족이고 불만족인 데이터는 일부일 것으로 추정됨(불균형(imbalanced)이 심한 데이터))\n",
    "\n",
    "## XGBoost\n",
    "트리 기반의 앙상블 학습 알고리즘 중 하나로, 대용량 데이터셋에서 높은 성능을 내는 데 특히 효과적"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b31fe1-987d-4df0-94db-98bf43b34fdc",
   "metadata": {},
   "source": [
    "## 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2fad0ea7-b13f-452b-a3e8-2a7037dc0793",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "cust_df = pd.read_csv('data/Customers_Satisfaction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cadffd14-4222-471b-ad80-fe29d525d0ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76020, 371)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>var3</th>\n",
       "      <th>var15</th>\n",
       "      <th>imp_ent_var16_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult3</th>\n",
       "      <th>imp_op_var40_comer_ult1</th>\n",
       "      <th>imp_op_var40_comer_ult3</th>\n",
       "      <th>imp_op_var40_efect_ult1</th>\n",
       "      <th>imp_op_var40_efect_ult3</th>\n",
       "      <th>...</th>\n",
       "      <th>saldo_medio_var33_hace2</th>\n",
       "      <th>saldo_medio_var33_hace3</th>\n",
       "      <th>saldo_medio_var33_ult1</th>\n",
       "      <th>saldo_medio_var33_ult3</th>\n",
       "      <th>saldo_medio_var44_hace2</th>\n",
       "      <th>saldo_medio_var44_hace3</th>\n",
       "      <th>saldo_medio_var44_ult1</th>\n",
       "      <th>saldo_medio_var44_ult3</th>\n",
       "      <th>var38</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39205.170000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49278.030000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67333.770000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64007.970000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117310.979016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 371 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  var3  var15  imp_ent_var16_ult1  imp_op_var39_comer_ult1  \\\n",
       "0   1     2     23                 0.0                      0.0   \n",
       "1   3     2     34                 0.0                      0.0   \n",
       "2   4     2     23                 0.0                      0.0   \n",
       "3   8     2     37                 0.0                    195.0   \n",
       "4  10     2     39                 0.0                      0.0   \n",
       "\n",
       "   imp_op_var39_comer_ult3  imp_op_var40_comer_ult1  imp_op_var40_comer_ult3  \\\n",
       "0                      0.0                      0.0                      0.0   \n",
       "1                      0.0                      0.0                      0.0   \n",
       "2                      0.0                      0.0                      0.0   \n",
       "3                    195.0                      0.0                      0.0   \n",
       "4                      0.0                      0.0                      0.0   \n",
       "\n",
       "   imp_op_var40_efect_ult1  imp_op_var40_efect_ult3  ...  \\\n",
       "0                      0.0                      0.0  ...   \n",
       "1                      0.0                      0.0  ...   \n",
       "2                      0.0                      0.0  ...   \n",
       "3                      0.0                      0.0  ...   \n",
       "4                      0.0                      0.0  ...   \n",
       "\n",
       "   saldo_medio_var33_hace2  saldo_medio_var33_hace3  saldo_medio_var33_ult1  \\\n",
       "0                      0.0                      0.0                     0.0   \n",
       "1                      0.0                      0.0                     0.0   \n",
       "2                      0.0                      0.0                     0.0   \n",
       "3                      0.0                      0.0                     0.0   \n",
       "4                      0.0                      0.0                     0.0   \n",
       "\n",
       "   saldo_medio_var33_ult3  saldo_medio_var44_hace2  saldo_medio_var44_hace3  \\\n",
       "0                     0.0                      0.0                      0.0   \n",
       "1                     0.0                      0.0                      0.0   \n",
       "2                     0.0                      0.0                      0.0   \n",
       "3                     0.0                      0.0                      0.0   \n",
       "4                     0.0                      0.0                      0.0   \n",
       "\n",
       "   saldo_medio_var44_ult1  saldo_medio_var44_ult3          var38  TARGET  \n",
       "0                     0.0                     0.0   39205.170000       0  \n",
       "1                     0.0                     0.0   49278.030000       0  \n",
       "2                     0.0                     0.0   67333.770000       0  \n",
       "3                     0.0                     0.0   64007.970000       0  \n",
       "4                     0.0                     0.0  117310.979016       0  \n",
       "\n",
       "[5 rows x 371 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 확인\n",
    "print(cust_df.shape)\n",
    "cust_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba1b7377-2646-47a0-b122-01b5fb0aff4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    73012\n",
      "1     3008\n",
      "Name: TARGET, dtype: int64\n",
      "0.0395685345961589\n"
     ]
    }
   ],
   "source": [
    "# TARGET 컬럼 불만족인값(1)의 갯수와 비율 확인\n",
    "print(cust_df['TARGET'].value_counts())\n",
    "print(cust_df['TARGET'].value_counts()[1]/len(cust_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ab1209b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2\n",
       "Name: var3, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cust_df['var3'].mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "baf27928-a5ea-4833-bd49-204b017e80fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# var3 컬럼에서 이상값 찾고 이상값을 가장 빈도수가 높은 값으로 바꾸기\n",
    "cust_df['var3'].describe()\n",
    "\n",
    "cust_df.loc[cust_df['var3'] == -999999, 'var3']= 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6c8dd7d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    76020.000000\n",
       "mean         2.716483\n",
       "std          9.447971\n",
       "min          0.000000\n",
       "25%          2.000000\n",
       "50%          2.000000\n",
       "75%          2.000000\n",
       "max        238.000000\n",
       "Name: var3, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cust_df['var3'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "90c85a28-63ae-4827-8199-bb469a540369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불필요한 컬럼(ID) 삭제\n",
    "cust_df = cust_df.drop(columns=['ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "353d6ed0-cb91-4df0-9946-f2e695cb6ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "피쳐 데이터 shape : (76020, 369)\n"
     ]
    }
   ],
   "source": [
    "# 피쳐 세트와 레이블 세트 분리. 슬라이싱을 사용해 분리할 것. y_label은 df의 마지막 컬럼\n",
    "X_features = cust_df.iloc[:,:-1]\n",
    "y_labels = cust_df.iloc[:,-1]\n",
    "print('피쳐 데이터 shape : {0}'.format(X_features.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b652e7c4-98f8-4935-9d3f-7d950074fad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#학습/테스트 데이터셋 분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_tr, x_te, y_tr, y_te = train_test_split(X_features, y_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cdca93b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function fit in module xgboost.sklearn:\n",
      "\n",
      "fit(self, X: Any, y: Any, *, sample_weight: Optional[Any] = None, base_margin: Optional[Any] = None, eval_set: Optional[Sequence[Tuple[Any, Any]]] = None, eval_metric: Union[str, Sequence[str], Callable[[numpy.ndarray, xgboost.core.DMatrix], Tuple[str, float]], NoneType] = None, early_stopping_rounds: Optional[int] = None, verbose: Union[bool, int, NoneType] = True, xgb_model: Union[xgboost.core.Booster, str, xgboost.sklearn.XGBModel, NoneType] = None, sample_weight_eval_set: Optional[Sequence[Any]] = None, base_margin_eval_set: Optional[Sequence[Any]] = None, feature_weights: Optional[Any] = None, callbacks: Optional[Sequence[xgboost.callback.TrainingCallback]] = None) -> 'XGBClassifier'\n",
      "    Fit gradient boosting classifier.\n",
      "    \n",
      "    Note that calling ``fit()`` multiple times will cause the model object to be\n",
      "    re-fit from scratch. To resume training from a previous checkpoint, explicitly\n",
      "    pass ``xgb_model`` argument.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    X :\n",
      "        Feature matrix\n",
      "    y :\n",
      "        Labels\n",
      "    sample_weight :\n",
      "        instance weights\n",
      "    base_margin :\n",
      "        global bias for each instance.\n",
      "    eval_set :\n",
      "        A list of (X, y) tuple pairs to use as validation sets, for which\n",
      "        metrics will be computed.\n",
      "        Validation metrics will help us track the performance of the model.\n",
      "    \n",
      "    eval_metric : str, list of str, or callable, optional\n",
      "        .. deprecated:: 1.6.0\n",
      "            Use `eval_metric` in :py:meth:`__init__` or :py:meth:`set_params` instead.\n",
      "    \n",
      "    early_stopping_rounds : int\n",
      "        .. deprecated:: 1.6.0\n",
      "            Use `early_stopping_rounds` in :py:meth:`__init__` or\n",
      "            :py:meth:`set_params` instead.\n",
      "    verbose :\n",
      "        If `verbose` is True and an evaluation set is used, the evaluation metric\n",
      "        measured on the validation set is printed to stdout at each boosting stage.\n",
      "        If `verbose` is an integer, the evaluation metric is printed at each `verbose`\n",
      "        boosting stage. The last boosting stage / the boosting stage found by using\n",
      "        `early_stopping_rounds` is also printed.\n",
      "    xgb_model :\n",
      "        file name of stored XGBoost model or 'Booster' instance XGBoost model to be\n",
      "        loaded before training (allows training continuation).\n",
      "    sample_weight_eval_set :\n",
      "        A list of the form [L_1, L_2, ..., L_n], where each L_i is an array like\n",
      "        object storing instance weights for the i-th validation set.\n",
      "    base_margin_eval_set :\n",
      "        A list of the form [M_1, M_2, ..., M_n], where each M_i is an array like\n",
      "        object storing base margin for the i-th validation set.\n",
      "    feature_weights :\n",
      "        Weight for each feature, defines the probability of each feature being\n",
      "        selected when colsample is being used.  All values must be greater than 0,\n",
      "        otherwise a `ValueError` is thrown.\n",
      "    \n",
      "    callbacks :\n",
      "        .. deprecated:: 1.6.0\n",
      "            Use `callbacks` in :py:meth:`__init__` or :py:meth:`set_params` instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(XGBClassifier.fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0604ee8-a418-4869-89b5-54206a9d8be1",
   "metadata": {},
   "source": [
    "## XGBoost 모델 학습과 하이퍼 파라미터 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fdfcb639-2ea1-4976-9fe8-0c5fae350640",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fit() got an unexpected keyword argument 'eval_metrics'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [54]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m xgb_clf \u001b[38;5;241m=\u001b[39m XGBClassifier()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#성능 평가 지표를 auc로, 조기 중단 파라미터는 100으로 설정하고 학습 수행\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[43mxgb_clf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mauc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m xgb_clf\u001b[38;5;241m.\u001b[39mfit(x_tr, y_tr)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# roc_score 구하기\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    619\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 620\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mTypeError\u001b[0m: fit() got an unexpected keyword argument 'eval_metrics'"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "xgb_clf = XGBClassifier()\n",
    "#성능 평가 지표를 auc로, 조기 중단 파라미터는 100으로 설정하고 학습 수행\n",
    "xgb_clf.fit(x_tr, y_tr, early_stopping_rounds=100, eval_metrics='auc')\n",
    "xgb_clf.fit(x_tr, y_tr)\n",
    "\n",
    "# roc_score 구하기\n",
    "xgb_roc_score = roc_auc_score(y_t)\n",
    "print('ROC AUC : {0:.4f}'.format(xgb_roc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d8b4cfcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class GridSearchCV in module sklearn.model_selection._search:\n",
      "\n",
      "class GridSearchCV(BaseSearchCV)\n",
      " |  GridSearchCV(estimator, param_grid, *, scoring=None, n_jobs=None, refit=True, cv=None, verbose=0, pre_dispatch='2*n_jobs', error_score=nan, return_train_score=False)\n",
      " |  \n",
      " |  Exhaustive search over specified parameter values for an estimator.\n",
      " |  \n",
      " |  Important members are fit, predict.\n",
      " |  \n",
      " |  GridSearchCV implements a \"fit\" and a \"score\" method.\n",
      " |  It also implements \"score_samples\", \"predict\", \"predict_proba\",\n",
      " |  \"decision_function\", \"transform\" and \"inverse_transform\" if they are\n",
      " |  implemented in the estimator used.\n",
      " |  \n",
      " |  The parameters of the estimator used to apply these methods are optimized\n",
      " |  by cross-validated grid-search over a parameter grid.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <grid_search>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  estimator : estimator object\n",
      " |      This is assumed to implement the scikit-learn estimator interface.\n",
      " |      Either estimator needs to provide a ``score`` function,\n",
      " |      or ``scoring`` must be passed.\n",
      " |  \n",
      " |  param_grid : dict or list of dictionaries\n",
      " |      Dictionary with parameters names (`str`) as keys and lists of\n",
      " |      parameter settings to try as values, or a list of such\n",
      " |      dictionaries, in which case the grids spanned by each dictionary\n",
      " |      in the list are explored. This enables searching over any sequence\n",
      " |      of parameter settings.\n",
      " |  \n",
      " |  scoring : str, callable, list, tuple or dict, default=None\n",
      " |      Strategy to evaluate the performance of the cross-validated model on\n",
      " |      the test set.\n",
      " |  \n",
      " |      If `scoring` represents a single score, one can use:\n",
      " |  \n",
      " |      - a single string (see :ref:`scoring_parameter`);\n",
      " |      - a callable (see :ref:`scoring`) that returns a single value.\n",
      " |  \n",
      " |      If `scoring` represents multiple scores, one can use:\n",
      " |  \n",
      " |      - a list or tuple of unique strings;\n",
      " |      - a callable returning a dictionary where the keys are the metric\n",
      " |        names and the values are the metric scores;\n",
      " |      - a dictionary with metric names as keys and callables a values.\n",
      " |  \n",
      " |      See :ref:`multimetric_grid_search` for an example.\n",
      " |  \n",
      " |  n_jobs : int, default=None\n",
      " |      Number of jobs to run in parallel.\n",
      " |      ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
      " |      ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
      " |      for more details.\n",
      " |  \n",
      " |      .. versionchanged:: v0.20\n",
      " |         `n_jobs` default changed from 1 to None\n",
      " |  \n",
      " |  refit : bool, str, or callable, default=True\n",
      " |      Refit an estimator using the best found parameters on the whole\n",
      " |      dataset.\n",
      " |  \n",
      " |      For multiple metric evaluation, this needs to be a `str` denoting the\n",
      " |      scorer that would be used to find the best parameters for refitting\n",
      " |      the estimator at the end.\n",
      " |  \n",
      " |      Where there are considerations other than maximum score in\n",
      " |      choosing a best estimator, ``refit`` can be set to a function which\n",
      " |      returns the selected ``best_index_`` given ``cv_results_``. In that\n",
      " |      case, the ``best_estimator_`` and ``best_params_`` will be set\n",
      " |      according to the returned ``best_index_`` while the ``best_score_``\n",
      " |      attribute will not be available.\n",
      " |  \n",
      " |      The refitted estimator is made available at the ``best_estimator_``\n",
      " |      attribute and permits using ``predict`` directly on this\n",
      " |      ``GridSearchCV`` instance.\n",
      " |  \n",
      " |      Also for multiple metric evaluation, the attributes ``best_index_``,\n",
      " |      ``best_score_`` and ``best_params_`` will only be available if\n",
      " |      ``refit`` is set and all of them will be determined w.r.t this specific\n",
      " |      scorer.\n",
      " |  \n",
      " |      See ``scoring`` parameter to know more about multiple metric\n",
      " |      evaluation.\n",
      " |  \n",
      " |      See :ref:`sphx_glr_auto_examples_model_selection_plot_grid_search_digits.py`\n",
      " |      to see how to design a custom selection strategy using a callable\n",
      " |      via `refit`.\n",
      " |  \n",
      " |      .. versionchanged:: 0.20\n",
      " |          Support for callable added.\n",
      " |  \n",
      " |  cv : int, cross-validation generator or an iterable, default=None\n",
      " |      Determines the cross-validation splitting strategy.\n",
      " |      Possible inputs for cv are:\n",
      " |  \n",
      " |      - None, to use the default 5-fold cross validation,\n",
      " |      - integer, to specify the number of folds in a `(Stratified)KFold`,\n",
      " |      - :term:`CV splitter`,\n",
      " |      - An iterable yielding (train, test) splits as arrays of indices.\n",
      " |  \n",
      " |      For integer/None inputs, if the estimator is a classifier and ``y`` is\n",
      " |      either binary or multiclass, :class:`StratifiedKFold` is used. In all\n",
      " |      other cases, :class:`KFold` is used. These splitters are instantiated\n",
      " |      with `shuffle=False` so the splits will be the same across calls.\n",
      " |  \n",
      " |      Refer :ref:`User Guide <cross_validation>` for the various\n",
      " |      cross-validation strategies that can be used here.\n",
      " |  \n",
      " |      .. versionchanged:: 0.22\n",
      " |          ``cv`` default value if None changed from 3-fold to 5-fold.\n",
      " |  \n",
      " |  verbose : int\n",
      " |      Controls the verbosity: the higher, the more messages.\n",
      " |  \n",
      " |      - >1 : the computation time for each fold and parameter candidate is\n",
      " |        displayed;\n",
      " |      - >2 : the score is also displayed;\n",
      " |      - >3 : the fold and candidate parameter indexes are also displayed\n",
      " |        together with the starting time of the computation.\n",
      " |  \n",
      " |  pre_dispatch : int, or str, default='2*n_jobs'\n",
      " |      Controls the number of jobs that get dispatched during parallel\n",
      " |      execution. Reducing this number can be useful to avoid an\n",
      " |      explosion of memory consumption when more jobs get dispatched\n",
      " |      than CPUs can process. This parameter can be:\n",
      " |  \n",
      " |          - None, in which case all the jobs are immediately\n",
      " |            created and spawned. Use this for lightweight and\n",
      " |            fast-running jobs, to avoid delays due to on-demand\n",
      " |            spawning of the jobs\n",
      " |  \n",
      " |          - An int, giving the exact number of total jobs that are\n",
      " |            spawned\n",
      " |  \n",
      " |          - A str, giving an expression as a function of n_jobs,\n",
      " |            as in '2*n_jobs'\n",
      " |  \n",
      " |  error_score : 'raise' or numeric, default=np.nan\n",
      " |      Value to assign to the score if an error occurs in estimator fitting.\n",
      " |      If set to 'raise', the error is raised. If a numeric value is given,\n",
      " |      FitFailedWarning is raised. This parameter does not affect the refit\n",
      " |      step, which will always raise the error.\n",
      " |  \n",
      " |  return_train_score : bool, default=False\n",
      " |      If ``False``, the ``cv_results_`` attribute will not include training\n",
      " |      scores.\n",
      " |      Computing training scores is used to get insights on how different\n",
      " |      parameter settings impact the overfitting/underfitting trade-off.\n",
      " |      However computing the scores on the training set can be computationally\n",
      " |      expensive and is not strictly required to select the parameters that\n",
      " |      yield the best generalization performance.\n",
      " |  \n",
      " |      .. versionadded:: 0.19\n",
      " |  \n",
      " |      .. versionchanged:: 0.21\n",
      " |          Default value was changed from ``True`` to ``False``\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  cv_results_ : dict of numpy (masked) ndarrays\n",
      " |      A dict with keys as column headers and values as columns, that can be\n",
      " |      imported into a pandas ``DataFrame``.\n",
      " |  \n",
      " |      For instance the below given table\n",
      " |  \n",
      " |      +------------+-----------+------------+-----------------+---+---------+\n",
      " |      |param_kernel|param_gamma|param_degree|split0_test_score|...|rank_t...|\n",
      " |      +============+===========+============+=================+===+=========+\n",
      " |      |  'poly'    |     --    |      2     |       0.80      |...|    2    |\n",
      " |      +------------+-----------+------------+-----------------+---+---------+\n",
      " |      |  'poly'    |     --    |      3     |       0.70      |...|    4    |\n",
      " |      +------------+-----------+------------+-----------------+---+---------+\n",
      " |      |  'rbf'     |     0.1   |     --     |       0.80      |...|    3    |\n",
      " |      +------------+-----------+------------+-----------------+---+---------+\n",
      " |      |  'rbf'     |     0.2   |     --     |       0.93      |...|    1    |\n",
      " |      +------------+-----------+------------+-----------------+---+---------+\n",
      " |  \n",
      " |      will be represented by a ``cv_results_`` dict of::\n",
      " |  \n",
      " |          {\n",
      " |          'param_kernel': masked_array(data = ['poly', 'poly', 'rbf', 'rbf'],\n",
      " |                                       mask = [False False False False]...)\n",
      " |          'param_gamma': masked_array(data = [-- -- 0.1 0.2],\n",
      " |                                      mask = [ True  True False False]...),\n",
      " |          'param_degree': masked_array(data = [2.0 3.0 -- --],\n",
      " |                                       mask = [False False  True  True]...),\n",
      " |          'split0_test_score'  : [0.80, 0.70, 0.80, 0.93],\n",
      " |          'split1_test_score'  : [0.82, 0.50, 0.70, 0.78],\n",
      " |          'mean_test_score'    : [0.81, 0.60, 0.75, 0.85],\n",
      " |          'std_test_score'     : [0.01, 0.10, 0.05, 0.08],\n",
      " |          'rank_test_score'    : [2, 4, 3, 1],\n",
      " |          'split0_train_score' : [0.80, 0.92, 0.70, 0.93],\n",
      " |          'split1_train_score' : [0.82, 0.55, 0.70, 0.87],\n",
      " |          'mean_train_score'   : [0.81, 0.74, 0.70, 0.90],\n",
      " |          'std_train_score'    : [0.01, 0.19, 0.00, 0.03],\n",
      " |          'mean_fit_time'      : [0.73, 0.63, 0.43, 0.49],\n",
      " |          'std_fit_time'       : [0.01, 0.02, 0.01, 0.01],\n",
      " |          'mean_score_time'    : [0.01, 0.06, 0.04, 0.04],\n",
      " |          'std_score_time'     : [0.00, 0.00, 0.00, 0.01],\n",
      " |          'params'             : [{'kernel': 'poly', 'degree': 2}, ...],\n",
      " |          }\n",
      " |  \n",
      " |      NOTE\n",
      " |  \n",
      " |      The key ``'params'`` is used to store a list of parameter\n",
      " |      settings dicts for all the parameter candidates.\n",
      " |  \n",
      " |      The ``mean_fit_time``, ``std_fit_time``, ``mean_score_time`` and\n",
      " |      ``std_score_time`` are all in seconds.\n",
      " |  \n",
      " |      For multi-metric evaluation, the scores for all the scorers are\n",
      " |      available in the ``cv_results_`` dict at the keys ending with that\n",
      " |      scorer's name (``'_<scorer_name>'``) instead of ``'_score'`` shown\n",
      " |      above. ('split0_test_precision', 'mean_train_precision' etc.)\n",
      " |  \n",
      " |  best_estimator_ : estimator\n",
      " |      Estimator that was chosen by the search, i.e. estimator\n",
      " |      which gave highest score (or smallest loss if specified)\n",
      " |      on the left out data. Not available if ``refit=False``.\n",
      " |  \n",
      " |      See ``refit`` parameter for more information on allowed values.\n",
      " |  \n",
      " |  best_score_ : float\n",
      " |      Mean cross-validated score of the best_estimator\n",
      " |  \n",
      " |      For multi-metric evaluation, this is present only if ``refit`` is\n",
      " |      specified.\n",
      " |  \n",
      " |      This attribute is not available if ``refit`` is a function.\n",
      " |  \n",
      " |  best_params_ : dict\n",
      " |      Parameter setting that gave the best results on the hold out data.\n",
      " |  \n",
      " |      For multi-metric evaluation, this is present only if ``refit`` is\n",
      " |      specified.\n",
      " |  \n",
      " |  best_index_ : int\n",
      " |      The index (of the ``cv_results_`` arrays) which corresponds to the best\n",
      " |      candidate parameter setting.\n",
      " |  \n",
      " |      The dict at ``search.cv_results_['params'][search.best_index_]`` gives\n",
      " |      the parameter setting for the best model, that gives the highest\n",
      " |      mean score (``search.best_score_``).\n",
      " |  \n",
      " |      For multi-metric evaluation, this is present only if ``refit`` is\n",
      " |      specified.\n",
      " |  \n",
      " |  scorer_ : function or a dict\n",
      " |      Scorer function used on the held out data to choose the best\n",
      " |      parameters for the model.\n",
      " |  \n",
      " |      For multi-metric evaluation, this attribute holds the validated\n",
      " |      ``scoring`` dict which maps the scorer key to the scorer callable.\n",
      " |  \n",
      " |  n_splits_ : int\n",
      " |      The number of cross-validation splits (folds/iterations).\n",
      " |  \n",
      " |  refit_time_ : float\n",
      " |      Seconds used for refitting the best model on the whole dataset.\n",
      " |  \n",
      " |      This is present only if ``refit`` is not False.\n",
      " |  \n",
      " |      .. versionadded:: 0.20\n",
      " |  \n",
      " |  multimetric_ : bool\n",
      " |      Whether or not the scorers compute several metrics.\n",
      " |  \n",
      " |  classes_ : ndarray of shape (n_classes,)\n",
      " |      The classes labels. This is present only if ``refit`` is specified and\n",
      " |      the underlying estimator is a classifier.\n",
      " |  \n",
      " |  n_features_in_ : int\n",
      " |      Number of features seen during :term:`fit`. Only defined if\n",
      " |      `best_estimator_` is defined (see the documentation for the `refit`\n",
      " |      parameter for more details) and that `best_estimator_` exposes\n",
      " |      `n_features_in_` when fit.\n",
      " |  \n",
      " |      .. versionadded:: 0.24\n",
      " |  \n",
      " |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      " |      Names of features seen during :term:`fit`. Only defined if\n",
      " |      `best_estimator_` is defined (see the documentation for the `refit`\n",
      " |      parameter for more details) and that `best_estimator_` exposes\n",
      " |      `feature_names_in_` when fit.\n",
      " |  \n",
      " |      .. versionadded:: 1.0\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  ParameterGrid : Generates all the combinations of a hyperparameter grid.\n",
      " |  train_test_split : Utility function to split the data into a development\n",
      " |      set usable for fitting a GridSearchCV instance and an evaluation set\n",
      " |      for its final evaluation.\n",
      " |  sklearn.metrics.make_scorer : Make a scorer from a performance metric or\n",
      " |      loss function.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The parameters selected are those that maximize the score of the left out\n",
      " |  data, unless an explicit score is passed in which case it is used instead.\n",
      " |  \n",
      " |  If `n_jobs` was set to a value higher than one, the data is copied for each\n",
      " |  point in the grid (and not `n_jobs` times). This is done for efficiency\n",
      " |  reasons if individual jobs take very little time, but may raise errors if\n",
      " |  the dataset is large and not enough memory is available.  A workaround in\n",
      " |  this case is to set `pre_dispatch`. Then, the memory is copied only\n",
      " |  `pre_dispatch` many times. A reasonable value for `pre_dispatch` is `2 *\n",
      " |  n_jobs`.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn import svm, datasets\n",
      " |  >>> from sklearn.model_selection import GridSearchCV\n",
      " |  >>> iris = datasets.load_iris()\n",
      " |  >>> parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
      " |  >>> svc = svm.SVC()\n",
      " |  >>> clf = GridSearchCV(svc, parameters)\n",
      " |  >>> clf.fit(iris.data, iris.target)\n",
      " |  GridSearchCV(estimator=SVC(),\n",
      " |               param_grid={'C': [1, 10], 'kernel': ('linear', 'rbf')})\n",
      " |  >>> sorted(clf.cv_results_.keys())\n",
      " |  ['mean_fit_time', 'mean_score_time', 'mean_test_score',...\n",
      " |   'param_C', 'param_kernel', 'params',...\n",
      " |   'rank_test_score', 'split0_test_score',...\n",
      " |   'split2_test_score', ...\n",
      " |   'std_fit_time', 'std_score_time', 'std_test_score']\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      GridSearchCV\n",
      " |      BaseSearchCV\n",
      " |      sklearn.base.MetaEstimatorMixin\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, estimator, param_grid, *, scoring=None, n_jobs=None, refit=True, cv=None, verbose=0, pre_dispatch='2*n_jobs', error_score=nan, return_train_score=False)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseSearchCV:\n",
      " |  \n",
      " |  decision_function(self, X)\n",
      " |      Call decision_function on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if ``refit=True`` and the underlying estimator supports\n",
      " |      ``decision_function``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y_score : ndarray of shape (n_samples,) or (n_samples, n_classes)                 or (n_samples, n_classes * (n_classes-1) / 2)\n",
      " |          Result of the decision function for `X` based on the estimator with\n",
      " |          the best found parameters.\n",
      " |  \n",
      " |  fit(self, X, y=None, *, groups=None, **fit_params)\n",
      " |      Run fit with all sets of parameters.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      \n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Training vector, where `n_samples` is the number of samples and\n",
      " |          `n_features` is the number of features.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples, n_output)             or (n_samples,), default=None\n",
      " |          Target relative to X for classification or regression;\n",
      " |          None for unsupervised learning.\n",
      " |      \n",
      " |      groups : array-like of shape (n_samples,), default=None\n",
      " |          Group labels for the samples used while splitting the dataset into\n",
      " |          train/test set. Only used in conjunction with a \"Group\" :term:`cv`\n",
      " |          instance (e.g., :class:`~sklearn.model_selection.GroupKFold`).\n",
      " |      \n",
      " |      **fit_params : dict of str -> object\n",
      " |          Parameters passed to the `fit` method of the estimator.\n",
      " |      \n",
      " |          If a fit parameter is an array-like whose length is equal to\n",
      " |          `num_samples` then it will be split across CV groups along with `X`\n",
      " |          and `y`. For example, the :term:`sample_weight` parameter is split\n",
      " |          because `len(sample_weights) = len(X)`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Instance of fitted estimator.\n",
      " |  \n",
      " |  inverse_transform(self, Xt)\n",
      " |      Call inverse_transform on the estimator with the best found params.\n",
      " |      \n",
      " |      Only available if the underlying estimator implements\n",
      " |      ``inverse_transform`` and ``refit=True``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      Xt : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X : {ndarray, sparse matrix} of shape (n_samples, n_features)\n",
      " |          Result of the `inverse_transform` function for `Xt` based on the\n",
      " |          estimator with the best found parameters.\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Call predict on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if ``refit=True`` and the underlying estimator supports\n",
      " |      ``predict``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y_pred : ndarray of shape (n_samples,)\n",
      " |          The predicted labels or values for `X` based on the estimator with\n",
      " |          the best found parameters.\n",
      " |  \n",
      " |  predict_log_proba(self, X)\n",
      " |      Call predict_log_proba on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if ``refit=True`` and the underlying estimator supports\n",
      " |      ``predict_log_proba``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y_pred : ndarray of shape (n_samples,) or (n_samples, n_classes)\n",
      " |          Predicted class log-probabilities for `X` based on the estimator\n",
      " |          with the best found parameters. The order of the classes\n",
      " |          corresponds to that in the fitted attribute :term:`classes_`.\n",
      " |  \n",
      " |  predict_proba(self, X)\n",
      " |      Call predict_proba on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if ``refit=True`` and the underlying estimator supports\n",
      " |      ``predict_proba``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y_pred : ndarray of shape (n_samples,) or (n_samples, n_classes)\n",
      " |          Predicted class probabilities for `X` based on the estimator with\n",
      " |          the best found parameters. The order of the classes corresponds\n",
      " |          to that in the fitted attribute :term:`classes_`.\n",
      " |  \n",
      " |  score(self, X, y=None)\n",
      " |      Return the score on the given data, if the estimator has been refit.\n",
      " |      \n",
      " |      This uses the score defined by ``scoring`` where provided, and the\n",
      " |      ``best_estimator_.score`` method otherwise.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Input data, where `n_samples` is the number of samples and\n",
      " |          `n_features` is the number of features.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples, n_output)             or (n_samples,), default=None\n",
      " |          Target relative to X for classification or regression;\n",
      " |          None for unsupervised learning.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          The score defined by ``scoring`` if provided, and the\n",
      " |          ``best_estimator_.score`` method otherwise.\n",
      " |  \n",
      " |  score_samples(self, X)\n",
      " |      Call score_samples on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if ``refit=True`` and the underlying estimator supports\n",
      " |      ``score_samples``.\n",
      " |      \n",
      " |      .. versionadded:: 0.24\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : iterable\n",
      " |          Data to predict on. Must fulfill input requirements\n",
      " |          of the underlying estimator.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y_score : ndarray of shape (n_samples,)\n",
      " |          The ``best_estimator_.score_samples`` method.\n",
      " |  \n",
      " |  transform(self, X)\n",
      " |      Call transform on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if the underlying estimator supports ``transform`` and\n",
      " |      ``refit=True``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Xt : {ndarray, sparse matrix} of shape (n_samples, n_features)\n",
      " |          `X` transformed in the new space based on the estimator with\n",
      " |          the best found parameters.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from BaseSearchCV:\n",
      " |  \n",
      " |  classes_\n",
      " |      Class labels.\n",
      " |      \n",
      " |      Only available when `refit=True` and the estimator is a classifier.\n",
      " |  \n",
      " |  n_features_in_\n",
      " |      Number of features seen during :term:`fit`.\n",
      " |      \n",
      " |      Only available when `refit=True`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.MetaEstimatorMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      " |      possible to update each component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "23a3a100-5d4b-473c-8968-d68f3ef84fce",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 2 required positional arguments: 'estimator' and 'param_grid'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [50]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m xgb_clf \u001b[38;5;241m=\u001b[39m XGBClassifier(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# 파라미터는 max_depth, min_child_weight, colsample_bytree를 사용\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# params = {max_depth=[10,100,200], min_child_weight= [0,1,2], colsample_bytree=[0.1,0.5, 0.8]\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     \n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# }\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# cv는 3으로 지정\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m gridcv \u001b[38;5;241m=\u001b[39m \u001b[43mGridSearchCV\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# 조기 중단 30, 평가지표로 auc 활용해 gridcv 학습 -> 실행하지 말 것\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# gridcv.fit()\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGridSearchCV 최적 파라미터 : \u001b[39m\u001b[38;5;124m'\u001b[39m, gridcv\u001b[38;5;241m.\u001b[39mbest_params_)\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() missing 2 required positional arguments: 'estimator' and 'param_grid'"
     ]
    }
   ],
   "source": [
    "# 하이퍼 파리미터 튜닝\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#하이퍼 파라미터 테스트의 수행 속도를 향상시키기 위해 n_estimators를 100으로 설정\n",
    "xgb_clf = XGBClassifier(n_estimators=100)\n",
    "\n",
    "# 파라미터는 max_depth, min_child_weight, colsample_bytree를 사용\n",
    "params = {max_depth=[10,20,30], min_child_weight= [0,1,2], colsample_bytree=[0.1,0.5, 0.8]\n",
    "    \n",
    "}\n",
    "\n",
    "# cv는 3으로 지정\n",
    "gridcv = GridSearchCV(cv=3)\n",
    "\n",
    "# 조기 중단 30, 평가지표로 auc 활용해 gridcv 학습 -> 실행하지 말 것\n",
    "# gridcv.fit()\n",
    "\n",
    "print('GridSearchCV 최적 파라미터 : ', gridcv.best_params_)\n",
    "#약 15분 소요\n",
    "\n",
    "# 결과\n",
    "# GridSearchCV 최적 파라미터 :  {'colsample_bytree': 0.5, 'max_depth': 5, 'min_child_weight': 3}\n",
    "# ROC AUC : 0.8445"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "76285eda-7dd8-4212-8911-13a5d188b34b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:52:36] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0fdc6d574b9c0d168-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:767: \n",
      "Parameters: { \"learning_rates\" } are not used.\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "roc_auc_score() missing 2 required positional arguments: 'y_true' and 'y_score'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [53]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#성능 평가 지표를 auc로, 조기 중단 파라미터 값은 200으로 설정하는 학습 수행\u001b[39;00m\n\u001b[0;32m      6\u001b[0m xgb_clf\u001b[38;5;241m.\u001b[39mfit(x_tr, y_tr)\n\u001b[1;32m----> 8\u001b[0m xgb_roc_score \u001b[38;5;241m=\u001b[39m \u001b[43mroc_auc_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mROC AUC : \u001b[39m\u001b[38;5;132;01m{0:.4f}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(xgb_roc_score))\n",
      "\u001b[1;31mTypeError\u001b[0m: roc_auc_score() missing 2 required positional arguments: 'y_true' and 'y_score'"
     ]
    }
   ],
   "source": [
    "# 위 결과와 아래 값을 토대로 최적의 파라미터를 가진 새로운 모델 생성\n",
    "# n_estimators는 1000, learning_rates는0.02, reg_alpha=0.03\n",
    "xgb_clf = XGBClassifier(n_estimators=1000, max_depth=10, reg_alpha=0.03)\n",
    "\n",
    "#성능 평가 지표를 auc로, 조기 중단 파라미터 값은 200으로 설정하는 학습 수행\n",
    "xgb_clf.fit(x_tr, y_tr)\n",
    "\n",
    "xgb_roc_score = roc_auc_score()\n",
    "print('ROC AUC : {0:.4f}'.format(xgb_roc_score))\n",
    "\n",
    "# ROC AUC : 0.8453"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "82544c9d-47c0-422a-a543-203a2328d8bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Feature importance'}, xlabel='F score', ylabel='Features'>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from xgboost import plot_importance\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "# xgboost plot_importance를 사용해 중요 feature 그래프 그리기\n",
    "plot_importance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e7fc2a1d-4d11-4779-95e0-40a689fae253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's auc: 0.817384\tvalid_0's binary_logloss: 0.165046\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\tvalid_0's auc: 0.818903\tvalid_0's binary_logloss: 0.160006\n",
      "[3]\tvalid_0's auc: 0.827707\tvalid_0's binary_logloss: 0.156323\n",
      "[4]\tvalid_0's auc: 0.832155\tvalid_0's binary_logloss: 0.153463\n",
      "[5]\tvalid_0's auc: 0.834677\tvalid_0's binary_logloss: 0.151256\n",
      "[6]\tvalid_0's auc: 0.834093\tvalid_0's binary_logloss: 0.149427\n",
      "[7]\tvalid_0's auc: 0.837046\tvalid_0's binary_logloss: 0.147961\n",
      "[8]\tvalid_0's auc: 0.837838\tvalid_0's binary_logloss: 0.146591\n",
      "[9]\tvalid_0's auc: 0.839435\tvalid_0's binary_logloss: 0.145455\n",
      "[10]\tvalid_0's auc: 0.83973\tvalid_0's binary_logloss: 0.144486\n",
      "[11]\tvalid_0's auc: 0.839799\tvalid_0's binary_logloss: 0.143769\n",
      "[12]\tvalid_0's auc: 0.840034\tvalid_0's binary_logloss: 0.143146\n",
      "[13]\tvalid_0's auc: 0.840271\tvalid_0's binary_logloss: 0.142533\n",
      "[14]\tvalid_0's auc: 0.840342\tvalid_0's binary_logloss: 0.142036\n",
      "[15]\tvalid_0's auc: 0.840928\tvalid_0's binary_logloss: 0.14161\n",
      "[16]\tvalid_0's auc: 0.840337\tvalid_0's binary_logloss: 0.141307\n",
      "[17]\tvalid_0's auc: 0.839901\tvalid_0's binary_logloss: 0.141152\n",
      "[18]\tvalid_0's auc: 0.839742\tvalid_0's binary_logloss: 0.141018\n",
      "[19]\tvalid_0's auc: 0.839818\tvalid_0's binary_logloss: 0.14068\n",
      "[20]\tvalid_0's auc: 0.839307\tvalid_0's binary_logloss: 0.140562\n",
      "[21]\tvalid_0's auc: 0.839662\tvalid_0's binary_logloss: 0.140353\n",
      "[22]\tvalid_0's auc: 0.840411\tvalid_0's binary_logloss: 0.140144\n",
      "[23]\tvalid_0's auc: 0.840522\tvalid_0's binary_logloss: 0.139983\n",
      "[24]\tvalid_0's auc: 0.840208\tvalid_0's binary_logloss: 0.139943\n",
      "[25]\tvalid_0's auc: 0.839578\tvalid_0's binary_logloss: 0.139898\n",
      "[26]\tvalid_0's auc: 0.83975\tvalid_0's binary_logloss: 0.139814\n",
      "[27]\tvalid_0's auc: 0.83988\tvalid_0's binary_logloss: 0.139711\n",
      "[28]\tvalid_0's auc: 0.839704\tvalid_0's binary_logloss: 0.139681\n",
      "[29]\tvalid_0's auc: 0.839432\tvalid_0's binary_logloss: 0.139662\n",
      "[30]\tvalid_0's auc: 0.839196\tvalid_0's binary_logloss: 0.139641\n",
      "[31]\tvalid_0's auc: 0.838891\tvalid_0's binary_logloss: 0.139654\n",
      "[32]\tvalid_0's auc: 0.838943\tvalid_0's binary_logloss: 0.1396\n",
      "[33]\tvalid_0's auc: 0.838632\tvalid_0's binary_logloss: 0.139642\n",
      "[34]\tvalid_0's auc: 0.838314\tvalid_0's binary_logloss: 0.139687\n",
      "[35]\tvalid_0's auc: 0.83844\tvalid_0's binary_logloss: 0.139668\n",
      "[36]\tvalid_0's auc: 0.839074\tvalid_0's binary_logloss: 0.139562\n",
      "[37]\tvalid_0's auc: 0.838806\tvalid_0's binary_logloss: 0.139594\n",
      "[38]\tvalid_0's auc: 0.839041\tvalid_0's binary_logloss: 0.139574\n",
      "[39]\tvalid_0's auc: 0.839081\tvalid_0's binary_logloss: 0.139587\n",
      "[40]\tvalid_0's auc: 0.839276\tvalid_0's binary_logloss: 0.139504\n",
      "[41]\tvalid_0's auc: 0.83951\tvalid_0's binary_logloss: 0.139481\n",
      "[42]\tvalid_0's auc: 0.839544\tvalid_0's binary_logloss: 0.139487\n",
      "[43]\tvalid_0's auc: 0.839673\tvalid_0's binary_logloss: 0.139478\n",
      "[44]\tvalid_0's auc: 0.839677\tvalid_0's binary_logloss: 0.139453\n",
      "[45]\tvalid_0's auc: 0.839703\tvalid_0's binary_logloss: 0.139445\n",
      "[46]\tvalid_0's auc: 0.839601\tvalid_0's binary_logloss: 0.139468\n",
      "[47]\tvalid_0's auc: 0.839318\tvalid_0's binary_logloss: 0.139529\n",
      "[48]\tvalid_0's auc: 0.839462\tvalid_0's binary_logloss: 0.139486\n",
      "[49]\tvalid_0's auc: 0.839288\tvalid_0's binary_logloss: 0.139492\n",
      "[50]\tvalid_0's auc: 0.838987\tvalid_0's binary_logloss: 0.139572\n",
      "[51]\tvalid_0's auc: 0.838845\tvalid_0's binary_logloss: 0.139603\n",
      "[52]\tvalid_0's auc: 0.838655\tvalid_0's binary_logloss: 0.139623\n",
      "[53]\tvalid_0's auc: 0.838783\tvalid_0's binary_logloss: 0.139609\n",
      "[54]\tvalid_0's auc: 0.838695\tvalid_0's binary_logloss: 0.139638\n",
      "[55]\tvalid_0's auc: 0.838868\tvalid_0's binary_logloss: 0.139625\n",
      "[56]\tvalid_0's auc: 0.838653\tvalid_0's binary_logloss: 0.139645\n",
      "[57]\tvalid_0's auc: 0.83856\tvalid_0's binary_logloss: 0.139688\n",
      "[58]\tvalid_0's auc: 0.838475\tvalid_0's binary_logloss: 0.139694\n",
      "[59]\tvalid_0's auc: 0.8384\tvalid_0's binary_logloss: 0.139682\n",
      "[60]\tvalid_0's auc: 0.838319\tvalid_0's binary_logloss: 0.13969\n",
      "[61]\tvalid_0's auc: 0.838209\tvalid_0's binary_logloss: 0.13973\n",
      "[62]\tvalid_0's auc: 0.83806\tvalid_0's binary_logloss: 0.139765\n",
      "[63]\tvalid_0's auc: 0.838096\tvalid_0's binary_logloss: 0.139749\n",
      "[64]\tvalid_0's auc: 0.838163\tvalid_0's binary_logloss: 0.139746\n",
      "[65]\tvalid_0's auc: 0.838183\tvalid_0's binary_logloss: 0.139805\n",
      "[66]\tvalid_0's auc: 0.838215\tvalid_0's binary_logloss: 0.139815\n",
      "[67]\tvalid_0's auc: 0.838268\tvalid_0's binary_logloss: 0.139822\n",
      "[68]\tvalid_0's auc: 0.83836\tvalid_0's binary_logloss: 0.139816\n",
      "[69]\tvalid_0's auc: 0.838114\tvalid_0's binary_logloss: 0.139874\n",
      "[70]\tvalid_0's auc: 0.83832\tvalid_0's binary_logloss: 0.139816\n",
      "[71]\tvalid_0's auc: 0.838256\tvalid_0's binary_logloss: 0.139818\n",
      "[72]\tvalid_0's auc: 0.838231\tvalid_0's binary_logloss: 0.139845\n",
      "[73]\tvalid_0's auc: 0.838028\tvalid_0's binary_logloss: 0.139888\n",
      "[74]\tvalid_0's auc: 0.837912\tvalid_0's binary_logloss: 0.139905\n",
      "[75]\tvalid_0's auc: 0.83772\tvalid_0's binary_logloss: 0.13992\n",
      "[76]\tvalid_0's auc: 0.837606\tvalid_0's binary_logloss: 0.139899\n",
      "[77]\tvalid_0's auc: 0.837521\tvalid_0's binary_logloss: 0.139925\n",
      "[78]\tvalid_0's auc: 0.837462\tvalid_0's binary_logloss: 0.139957\n",
      "[79]\tvalid_0's auc: 0.837541\tvalid_0's binary_logloss: 0.139944\n",
      "[80]\tvalid_0's auc: 0.838013\tvalid_0's binary_logloss: 0.13983\n",
      "[81]\tvalid_0's auc: 0.83789\tvalid_0's binary_logloss: 0.139874\n",
      "[82]\tvalid_0's auc: 0.837671\tvalid_0's binary_logloss: 0.139975\n",
      "[83]\tvalid_0's auc: 0.837707\tvalid_0's binary_logloss: 0.139972\n",
      "[84]\tvalid_0's auc: 0.837631\tvalid_0's binary_logloss: 0.140011\n",
      "[85]\tvalid_0's auc: 0.837496\tvalid_0's binary_logloss: 0.140023\n",
      "[86]\tvalid_0's auc: 0.83757\tvalid_0's binary_logloss: 0.140021\n",
      "[87]\tvalid_0's auc: 0.837284\tvalid_0's binary_logloss: 0.140099\n",
      "[88]\tvalid_0's auc: 0.837228\tvalid_0's binary_logloss: 0.140115\n",
      "[89]\tvalid_0's auc: 0.836964\tvalid_0's binary_logloss: 0.140172\n",
      "[90]\tvalid_0's auc: 0.836752\tvalid_0's binary_logloss: 0.140225\n",
      "[91]\tvalid_0's auc: 0.836833\tvalid_0's binary_logloss: 0.140221\n",
      "[92]\tvalid_0's auc: 0.836648\tvalid_0's binary_logloss: 0.140277\n",
      "[93]\tvalid_0's auc: 0.836648\tvalid_0's binary_logloss: 0.140315\n",
      "[94]\tvalid_0's auc: 0.836677\tvalid_0's binary_logloss: 0.140321\n",
      "[95]\tvalid_0's auc: 0.836729\tvalid_0's binary_logloss: 0.140307\n",
      "[96]\tvalid_0's auc: 0.8368\tvalid_0's binary_logloss: 0.140313\n",
      "[97]\tvalid_0's auc: 0.836797\tvalid_0's binary_logloss: 0.140331\n",
      "[98]\tvalid_0's auc: 0.836675\tvalid_0's binary_logloss: 0.140361\n",
      "[99]\tvalid_0's auc: 0.83655\tvalid_0's binary_logloss: 0.14039\n",
      "[100]\tvalid_0's auc: 0.836518\tvalid_0's binary_logloss: 0.1404\n",
      "[101]\tvalid_0's auc: 0.836998\tvalid_0's binary_logloss: 0.140294\n",
      "[102]\tvalid_0's auc: 0.836778\tvalid_0's binary_logloss: 0.140366\n",
      "[103]\tvalid_0's auc: 0.83694\tvalid_0's binary_logloss: 0.140333\n",
      "[104]\tvalid_0's auc: 0.836749\tvalid_0's binary_logloss: 0.14039\n",
      "[105]\tvalid_0's auc: 0.836752\tvalid_0's binary_logloss: 0.140391\n",
      "[106]\tvalid_0's auc: 0.837197\tvalid_0's binary_logloss: 0.140305\n",
      "[107]\tvalid_0's auc: 0.837141\tvalid_0's binary_logloss: 0.140329\n",
      "[108]\tvalid_0's auc: 0.8371\tvalid_0's binary_logloss: 0.140344\n",
      "[109]\tvalid_0's auc: 0.837136\tvalid_0's binary_logloss: 0.14033\n",
      "[110]\tvalid_0's auc: 0.837102\tvalid_0's binary_logloss: 0.140388\n",
      "[111]\tvalid_0's auc: 0.836957\tvalid_0's binary_logloss: 0.140426\n",
      "[112]\tvalid_0's auc: 0.836779\tvalid_0's binary_logloss: 0.14051\n",
      "[113]\tvalid_0's auc: 0.836831\tvalid_0's binary_logloss: 0.140526\n",
      "[114]\tvalid_0's auc: 0.836783\tvalid_0's binary_logloss: 0.14055\n",
      "[115]\tvalid_0's auc: 0.836672\tvalid_0's binary_logloss: 0.140585\n",
      "Early stopping, best iteration is:\n",
      "[15]\tvalid_0's auc: 0.840928\tvalid_0's binary_logloss: 0.14161\n",
      "ROC AUC : 0.8409\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "lgbm_clf = LGBMClassifier(n_estimators=500)\n",
    "\n",
    "evals = [(X_test, y_test)]\n",
    "lgbm_clf.fit(X_train, y_train, early_stopping_rounds=100, eval_metric='auc', eval_set=evals, verbose=True)\n",
    "\n",
    "lgbm_roc_score = roc_auc_score(y_test, lgbm_clf.predict_proba(X_test)[:, 1], average='macro')\n",
    "print('ROC AUC : {0:.4f}'.format(lgbm_roc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351c0bd9-5b49-417f-82d4-248c4a615c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GridSearchCV로 더 다양한 하이퍼 파라미터 튜닝 수행\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#하이퍼 파라미터 테스트의 수행 속도를 향상시키기 위해 n_estimators를 200으로 감소\n",
    "lgbm_clf = LGBMClassifier(n_estimators=200)\n",
    "\n",
    "params = {\n",
    "    'num_leaves' : [32, 64],\n",
    "    'max_depth' : [128, 160],\n",
    "    'min_child_samples' : [60, 100],\n",
    "    'subsample' : [0.8, 1]\n",
    "}\n",
    "\n",
    "#cv는 3으로 지정\n",
    "gridcv = GridSearchCV(lgbm_clf, param_grid=params, cv=3)\n",
    "gridcv.fit(X_train, y_train, early_stopping_rounds=30, eval_metric='auc', eval_set=[(X_train, y_train), (X_test, y_test)])\n",
    "\n",
    "print('GridSearchCV 최적 파라미터 : ', gridcv.best_params_)\n",
    "lgbm_roc_score = roc_auc_score(y_test, gridcv.predict_proba(X_test)[:, 1], average='macro')\n",
    "print('ROC AUC : {0:.4f}'.format(lgbm_roc_score))\n",
    "\n",
    "# GridSearchCV 최적 파라미터 :  {'max_depth': 128, 'min_child_samples': 100, 'num_leaves': 32, 'subsample': 0.8}\n",
    "# ROC AUC : 0.8417"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ea44d8d7-03cb-4c73-b3d3-6340a28375e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's auc: 0.819488\tvalid_0's binary_logloss: 0.165016\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\tvalid_0's auc: 0.822075\tvalid_0's binary_logloss: 0.159734\n",
      "[3]\tvalid_0's auc: 0.829436\tvalid_0's binary_logloss: 0.156119\n",
      "[4]\tvalid_0's auc: 0.836147\tvalid_0's binary_logloss: 0.153073\n",
      "[5]\tvalid_0's auc: 0.839041\tvalid_0's binary_logloss: 0.150773\n",
      "[6]\tvalid_0's auc: 0.839076\tvalid_0's binary_logloss: 0.148948\n",
      "[7]\tvalid_0's auc: 0.839943\tvalid_0's binary_logloss: 0.147346\n",
      "[8]\tvalid_0's auc: 0.84098\tvalid_0's binary_logloss: 0.146068\n",
      "[9]\tvalid_0's auc: 0.840686\tvalid_0's binary_logloss: 0.14506\n",
      "[10]\tvalid_0's auc: 0.841299\tvalid_0's binary_logloss: 0.144134\n",
      "[11]\tvalid_0's auc: 0.841659\tvalid_0's binary_logloss: 0.14327\n",
      "[12]\tvalid_0's auc: 0.841543\tvalid_0's binary_logloss: 0.14261\n",
      "[13]\tvalid_0's auc: 0.841645\tvalid_0's binary_logloss: 0.14205\n",
      "[14]\tvalid_0's auc: 0.841389\tvalid_0's binary_logloss: 0.14164\n",
      "[15]\tvalid_0's auc: 0.84154\tvalid_0's binary_logloss: 0.141254\n",
      "[16]\tvalid_0's auc: 0.841108\tvalid_0's binary_logloss: 0.140999\n",
      "[17]\tvalid_0's auc: 0.840563\tvalid_0's binary_logloss: 0.140752\n",
      "[18]\tvalid_0's auc: 0.839571\tvalid_0's binary_logloss: 0.140569\n",
      "[19]\tvalid_0's auc: 0.839656\tvalid_0's binary_logloss: 0.14032\n",
      "[20]\tvalid_0's auc: 0.839451\tvalid_0's binary_logloss: 0.140153\n",
      "[21]\tvalid_0's auc: 0.839806\tvalid_0's binary_logloss: 0.139937\n",
      "[22]\tvalid_0's auc: 0.839529\tvalid_0's binary_logloss: 0.13983\n",
      "[23]\tvalid_0's auc: 0.839217\tvalid_0's binary_logloss: 0.139727\n",
      "[24]\tvalid_0's auc: 0.838771\tvalid_0's binary_logloss: 0.139684\n",
      "[25]\tvalid_0's auc: 0.838891\tvalid_0's binary_logloss: 0.139609\n",
      "[26]\tvalid_0's auc: 0.839175\tvalid_0's binary_logloss: 0.139492\n",
      "[27]\tvalid_0's auc: 0.83916\tvalid_0's binary_logloss: 0.139441\n",
      "[28]\tvalid_0's auc: 0.838877\tvalid_0's binary_logloss: 0.139445\n",
      "[29]\tvalid_0's auc: 0.839368\tvalid_0's binary_logloss: 0.139322\n",
      "[30]\tvalid_0's auc: 0.838922\tvalid_0's binary_logloss: 0.139324\n",
      "[31]\tvalid_0's auc: 0.838453\tvalid_0's binary_logloss: 0.139316\n",
      "[32]\tvalid_0's auc: 0.838572\tvalid_0's binary_logloss: 0.139283\n",
      "[33]\tvalid_0's auc: 0.838535\tvalid_0's binary_logloss: 0.139271\n",
      "[34]\tvalid_0's auc: 0.83825\tvalid_0's binary_logloss: 0.139275\n",
      "[35]\tvalid_0's auc: 0.838533\tvalid_0's binary_logloss: 0.139208\n",
      "[36]\tvalid_0's auc: 0.838446\tvalid_0's binary_logloss: 0.139217\n",
      "[37]\tvalid_0's auc: 0.838379\tvalid_0's binary_logloss: 0.139221\n",
      "[38]\tvalid_0's auc: 0.838156\tvalid_0's binary_logloss: 0.139254\n",
      "[39]\tvalid_0's auc: 0.838432\tvalid_0's binary_logloss: 0.139181\n",
      "[40]\tvalid_0's auc: 0.838247\tvalid_0's binary_logloss: 0.139215\n",
      "[41]\tvalid_0's auc: 0.83826\tvalid_0's binary_logloss: 0.139218\n",
      "[42]\tvalid_0's auc: 0.838578\tvalid_0's binary_logloss: 0.139154\n",
      "[43]\tvalid_0's auc: 0.83859\tvalid_0's binary_logloss: 0.139169\n",
      "[44]\tvalid_0's auc: 0.838508\tvalid_0's binary_logloss: 0.139168\n",
      "[45]\tvalid_0's auc: 0.838529\tvalid_0's binary_logloss: 0.139115\n",
      "[46]\tvalid_0's auc: 0.838474\tvalid_0's binary_logloss: 0.139123\n",
      "[47]\tvalid_0's auc: 0.839008\tvalid_0's binary_logloss: 0.139046\n",
      "[48]\tvalid_0's auc: 0.838863\tvalid_0's binary_logloss: 0.139068\n",
      "[49]\tvalid_0's auc: 0.83888\tvalid_0's binary_logloss: 0.13906\n",
      "[50]\tvalid_0's auc: 0.838809\tvalid_0's binary_logloss: 0.139075\n",
      "[51]\tvalid_0's auc: 0.83859\tvalid_0's binary_logloss: 0.139096\n",
      "[52]\tvalid_0's auc: 0.838282\tvalid_0's binary_logloss: 0.139147\n",
      "[53]\tvalid_0's auc: 0.838288\tvalid_0's binary_logloss: 0.139141\n",
      "[54]\tvalid_0's auc: 0.838278\tvalid_0's binary_logloss: 0.139142\n",
      "[55]\tvalid_0's auc: 0.838434\tvalid_0's binary_logloss: 0.139125\n",
      "[56]\tvalid_0's auc: 0.838412\tvalid_0's binary_logloss: 0.139145\n",
      "[57]\tvalid_0's auc: 0.838626\tvalid_0's binary_logloss: 0.139127\n",
      "[58]\tvalid_0's auc: 0.838384\tvalid_0's binary_logloss: 0.139188\n",
      "[59]\tvalid_0's auc: 0.838063\tvalid_0's binary_logloss: 0.139236\n",
      "[60]\tvalid_0's auc: 0.838145\tvalid_0's binary_logloss: 0.13923\n",
      "[61]\tvalid_0's auc: 0.837988\tvalid_0's binary_logloss: 0.139245\n",
      "[62]\tvalid_0's auc: 0.838005\tvalid_0's binary_logloss: 0.139256\n",
      "[63]\tvalid_0's auc: 0.837845\tvalid_0's binary_logloss: 0.139268\n",
      "[64]\tvalid_0's auc: 0.837656\tvalid_0's binary_logloss: 0.139293\n",
      "[65]\tvalid_0's auc: 0.837549\tvalid_0's binary_logloss: 0.139317\n",
      "[66]\tvalid_0's auc: 0.83779\tvalid_0's binary_logloss: 0.139279\n",
      "[67]\tvalid_0's auc: 0.837827\tvalid_0's binary_logloss: 0.1393\n",
      "[68]\tvalid_0's auc: 0.837746\tvalid_0's binary_logloss: 0.13934\n",
      "[69]\tvalid_0's auc: 0.837685\tvalid_0's binary_logloss: 0.139328\n",
      "[70]\tvalid_0's auc: 0.837589\tvalid_0's binary_logloss: 0.139355\n",
      "[71]\tvalid_0's auc: 0.837816\tvalid_0's binary_logloss: 0.139335\n",
      "[72]\tvalid_0's auc: 0.837883\tvalid_0's binary_logloss: 0.139324\n",
      "[73]\tvalid_0's auc: 0.837614\tvalid_0's binary_logloss: 0.139416\n",
      "[74]\tvalid_0's auc: 0.837565\tvalid_0's binary_logloss: 0.139416\n",
      "[75]\tvalid_0's auc: 0.837359\tvalid_0's binary_logloss: 0.139475\n",
      "[76]\tvalid_0's auc: 0.837393\tvalid_0's binary_logloss: 0.139458\n",
      "[77]\tvalid_0's auc: 0.837358\tvalid_0's binary_logloss: 0.13945\n",
      "[78]\tvalid_0's auc: 0.837298\tvalid_0's binary_logloss: 0.139506\n",
      "[79]\tvalid_0's auc: 0.837193\tvalid_0's binary_logloss: 0.139552\n",
      "[80]\tvalid_0's auc: 0.836945\tvalid_0's binary_logloss: 0.1396\n",
      "[81]\tvalid_0's auc: 0.836893\tvalid_0's binary_logloss: 0.139662\n",
      "[82]\tvalid_0's auc: 0.836907\tvalid_0's binary_logloss: 0.139651\n",
      "[83]\tvalid_0's auc: 0.836779\tvalid_0's binary_logloss: 0.139714\n",
      "[84]\tvalid_0's auc: 0.836733\tvalid_0's binary_logloss: 0.139704\n",
      "[85]\tvalid_0's auc: 0.836814\tvalid_0's binary_logloss: 0.139706\n",
      "[86]\tvalid_0's auc: 0.836638\tvalid_0's binary_logloss: 0.139738\n",
      "[87]\tvalid_0's auc: 0.836471\tvalid_0's binary_logloss: 0.139816\n",
      "[88]\tvalid_0's auc: 0.836511\tvalid_0's binary_logloss: 0.139833\n",
      "[89]\tvalid_0's auc: 0.836355\tvalid_0's binary_logloss: 0.13986\n",
      "[90]\tvalid_0's auc: 0.836314\tvalid_0's binary_logloss: 0.139907\n",
      "[91]\tvalid_0's auc: 0.836143\tvalid_0's binary_logloss: 0.139945\n",
      "[92]\tvalid_0's auc: 0.836124\tvalid_0's binary_logloss: 0.139954\n",
      "[93]\tvalid_0's auc: 0.836073\tvalid_0's binary_logloss: 0.139961\n",
      "[94]\tvalid_0's auc: 0.83596\tvalid_0's binary_logloss: 0.139981\n",
      "[95]\tvalid_0's auc: 0.835924\tvalid_0's binary_logloss: 0.140014\n",
      "[96]\tvalid_0's auc: 0.835947\tvalid_0's binary_logloss: 0.140001\n",
      "[97]\tvalid_0's auc: 0.835798\tvalid_0's binary_logloss: 0.140069\n",
      "[98]\tvalid_0's auc: 0.835699\tvalid_0's binary_logloss: 0.140112\n",
      "[99]\tvalid_0's auc: 0.835598\tvalid_0's binary_logloss: 0.140139\n",
      "[100]\tvalid_0's auc: 0.835567\tvalid_0's binary_logloss: 0.140156\n",
      "[101]\tvalid_0's auc: 0.83541\tvalid_0's binary_logloss: 0.140183\n",
      "[102]\tvalid_0's auc: 0.835235\tvalid_0's binary_logloss: 0.140234\n",
      "[103]\tvalid_0's auc: 0.835304\tvalid_0's binary_logloss: 0.140213\n",
      "[104]\tvalid_0's auc: 0.834946\tvalid_0's binary_logloss: 0.140301\n",
      "[105]\tvalid_0's auc: 0.834578\tvalid_0's binary_logloss: 0.140374\n",
      "[106]\tvalid_0's auc: 0.834617\tvalid_0's binary_logloss: 0.140395\n",
      "[107]\tvalid_0's auc: 0.834575\tvalid_0's binary_logloss: 0.14042\n",
      "[108]\tvalid_0's auc: 0.834393\tvalid_0's binary_logloss: 0.140467\n",
      "[109]\tvalid_0's auc: 0.834307\tvalid_0's binary_logloss: 0.14051\n",
      "[110]\tvalid_0's auc: 0.834382\tvalid_0's binary_logloss: 0.14051\n",
      "[111]\tvalid_0's auc: 0.83436\tvalid_0's binary_logloss: 0.14054\n",
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's auc: 0.841659\tvalid_0's binary_logloss: 0.14327\n",
      "ROC AUC : 0.8417\n"
     ]
    }
   ],
   "source": [
    "#해당 하이퍼 파라미터를 LightGBM에 적용 후 다시 학습해 ROC-AUC 측정 결과 도출\n",
    "lgbm_clf = LGBMClassifier(n_estimators=1000, num_leaves=32, subsample=0.8, min_child_samples=100, max_depth=128)\n",
    "\n",
    "evals = [(X_test, y_test)]\n",
    "lgbm_clf.fit(X_train, y_train, early_stopping_rounds=100, eval_metric='auc', eval_set=evals, verbose=True)\n",
    "\n",
    "lgbm_roc_score = roc_auc_score(y_test, lgbm_clf.predict_proba(X_test)[:, 1], average='macro')\n",
    "print('ROC AUC : {0:.4f}'.format(lgbm_roc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba372d2-b3a1-4b42-b5b6-547d973f59d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
